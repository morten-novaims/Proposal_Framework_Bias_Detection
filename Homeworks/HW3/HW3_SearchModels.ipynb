{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import text_transformer as tt\n",
    "nltk.download('twitter_samples')\n",
    "from nltk.corpus import twitter_samples\n",
    "tweets = twitter_samples.docs()\n",
    "docs = [t['text'] for t in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_tweets = list(set(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverted Indexes\n",
    "__Build your own inverted indexes. Create a class that takes as input a\n",
    "query and retrieves all the documents that relate to it. This is related to\n",
    "the boolean search model we saw in class.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every document in the dataset preprocess the tweets with tokenization stemming and remove stop words, do some pre processing of #hashtags and @mentions. remove repeated tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tweets_processed = [tt.tokenizer(tweet) for tweet in unique_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tweets_processed = [tt.normalizer(tweet) for tweet in unique_tweets_processed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results are better without applying the stemmer\n",
    "#unique_tweets_processed = [tt.stemmer(tweet) for tweet in unique_tweets_processed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @Schafernaker: #bbbqt loved the scouser (i think) saying to David Cameron : \"Hiya David, Ya Alright mate\" LOL @Number10gov\n",
      "['rt', 'schafernaker', 'bbbqt', 'loved', 'scouser', 'think', 'saying', 'david', 'cameron', 'hiya', 'david', 'ya', 'alright', 'mate', 'lol', 'number10gov']\n"
     ]
    }
   ],
   "source": [
    "print(unique_tweets[0])\n",
    "print(unique_tweets_processed[0])\n",
    "# Hastags and mentions are removed, not sure this is the goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the inverted indexes for each doc(tweet) in the dataset after\n",
    "processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = {i:set() for i in set(tt.flatten(unique_tweets_processed))}\n",
    "\n",
    "for index, tweet in enumerate(unique_tweets_processed):\n",
    "    for word in tweet:\n",
    "        word_index[word].add(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{96, 16997, 7305, 18927, 2706, 14227, 15058, 4474, 8986, 3837, 2719}\n",
      "['queenofnaw', 'historywoman', 'spsammy', 'scepticalscot', 'softmutt', 'iainjwatson', 'gave', 'snp', 'yes', 'high', 'ground', 'let', 'last', 'two', 'years', 'amp', 'post']\n",
      "@QueenOfNaw @Historywoman @spsammy @scepticalscot @softmutt @iainjwatson Gave SNP the \"Yes\" high ground, let it last two years, &amp; F.P. Post\n"
     ]
    }
   ],
   "source": [
    "print(word_index[\"seven\"])\n",
    "print(unique_tweets_processed[1585])\n",
    "print(unique_tweets[1585])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a boolean based query search method. with ands and ors.  \n",
    "* Return the documents that match “Farage” and “EU”\n",
    "* Return the documents that match “camera” or “photo”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e18337d2052469c839316464d903b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='Farage')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7da044ac12b45a0af5fa4e2be30f153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(options=('and', 'or'), value='and')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d13d7f315de4457f9302e109c7417e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='EU')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6ffd56949449fe95c3a546b9828513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Submit', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "668cb8318006438297ad934396d8a1d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='Tweets', layout=Layout(height='120px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Farage and EU\n",
      "Found 63 tweets\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ipywidgets import widgets\n",
    "text1 = widgets.Text(value=\"Farage\")\n",
    "options = widgets.RadioButtons(options=['and', 'or'])\n",
    "text2 = widgets.Text(value=\"EU\")\n",
    "submit_button = widgets.Button(description=\"Submit\")\n",
    "\n",
    "def action(words):\n",
    "    print(text1.value,options.value,text2.value)\n",
    "    textArea.value = \"\"\n",
    "    if text1.value.lower() not in word_index and text2.value.lower() not in word_index:\n",
    "        selected_tweets = []\n",
    "        \n",
    "    elif options.value == \"and\":\n",
    "        if text1.value.lower() not in word_index or text2.value.lower() not in word_index:\n",
    "            selected_tweets = []        \n",
    "        else:\n",
    "            selected_tweets = word_index[text1.value.lower()] & word_index[text2.value.lower()]\n",
    "    else:\n",
    "        if text1.value.lower() not in word_index:\n",
    "            selected_tweets = word_index[text2.value.lower()]\n",
    "        elif text2.value.lower() not in word_index:\n",
    "            selected_tweets = word_index[text1.value.lower()]     \n",
    "        else:\n",
    "            selected_tweets = word_index[text1.value.lower()] | word_index[text2.value.lower()] \n",
    "    print(\"Found {} tweets\\n\".format(len(selected_tweets)))\n",
    "    textArea.value = str([unique_tweets[tweet_id] for tweet_id in selected_tweets])\n",
    "                        \n",
    "textArea = widgets.Textarea(\n",
    "    value='Tweets',\n",
    "    layout=widgets.Layout(width='100%', height='120px'),\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "widgets = [text1, options, text2, submit_button, textArea]\n",
    "[display(widget) for widget in widgets]\n",
    "text1.on_submit(action)\n",
    "text2.on_submit(action)\n",
    "submit_button.on_click(action)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
