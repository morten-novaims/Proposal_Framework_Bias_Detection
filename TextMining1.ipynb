{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of TextMining1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/morten-novaims/Text_Mining_HW/blob/master/TextMining1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "4Vk9JZzfhVMi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Text Mining - Class 1\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "_Yk_wftShsjn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Basic text processing (Grep exercise)\n",
        "\n",
        "Download the document https://drive.google.com/file/d/1ESCJYl2qa-xF-\n",
        "rCWEaL-eQ2Spp_JAEh-/view?usp=sharing and explore the grep/awk command:"
      ]
    },
    {
      "metadata": {
        "id": "eApWgsdRGx_Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "24LgANY_K5z-",
        "colab_type": "code",
        "outputId": "6b8f4838-bdd7-4b00-ec67-04df356ee2ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "cell_type": "code",
      "source": [
        "# Download a file based on its file ID.\n",
        "#\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "file_id = '1ESCJYl2qa-xF-rCWEaL-eQ2Spp_JAEh-'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "wiki = downloaded.GetContentString()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-e2a8a0eb45d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfile_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1ESCJYl2qa-xF-rCWEaL-eQ2Spp_JAEh-'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdownloaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCreateFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfile_id\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mwiki\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownloaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetContentString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'drive' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "SUQa3rYoLM_n",
        "colab_type": "code",
        "outputId": "3c747a37-ee02-4ece-f7f9-01ed68f915ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Create a local file to perfr.\n",
        "with open('wiki.txt', 'w') as f:\n",
        "  f.write(wiki)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hi!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yfXnhcRAhzha",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1. Find how many lines exist in the document.  \n",
        "1. Count how many time each word occurs:  \n",
        "  1. mining  \n",
        "  1. textual  \n",
        "  1. term  \n",
        "1. (Optional extra 10 points) Extract only the last word of each sentence."
      ]
    },
    {
      "metadata": {
        "id": "PjZsu3rKuEQe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__*grep and awk not working in colab*__\n"
      ]
    },
    {
      "metadata": {
        "id": "u045pDGlMCuT",
        "colab_type": "code",
        "outputId": "48471e7b-a2b1-413e-874d-c19dadd5c511",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "!echo \"Total lines\"\n",
        "!wc -l wiki.txt\n",
        "!echo \"How many times mining appears\"\n",
        "!grep -o mining | wc -l\n",
        "!echo \"How many times textual appears\"\n",
        "!grep -o textual | wc -l\n",
        "!echo \"How many times term appers\"\n",
        "!grep -o term | wc -l\n",
        "!echo \"The last word of each line:\"\n",
        "!awk 'NF>1{print $NF}'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total lines\n",
            "128 wiki.txt\n",
            "How many times mining appears\n",
            "How many times textual appears\n",
            "How many times term appers\n",
            "The last word of each line:\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S5pWhTNTik39",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Basic Text Processing (re module)"
      ]
    },
    {
      "metadata": {
        "id": "JhxVNKQPDvfy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Get to know your regex:\n",
        "\n",
        "For the sentence:\n",
        "“ :) A smile to end up your day with. =) What is making you happy :))))))\n",
        "these days? <3 :DDDD ”\n",
        "\n",
        "1.1 Find every occurrence of a smiley :), ;), =), :)))))), :D, :DDDD and\n",
        "replace it with the word happy\n",
        "\n",
        "1.2 Find every occurrence of a number and replace it with the word digit\n",
        "in this document: https://drive.google.com/file/d/\n",
        "1hTJGWBXgVSBZlZ8klcVz7T59LeH7ncIq/view?usp=sharing\n",
        "\n",
        "1.3 Create a regex for identifying punctuation marks (all kinds)"
      ]
    },
    {
      "metadata": {
        "id": "6Q7sHY-LE5US",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## import the regex module first to use regex\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eKlWP5J7ikTU",
        "colab_type": "code",
        "outputId": "11e530a1-fd29-485d-e6e6-7c9176fc6fb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "## Question 1.1: Find every occurrence of a smiley :), ;), =), :)))))), :D, :DDDD and replace it with the word happy\n",
        "\n",
        "# add the sentence and the characters into a variable\n",
        "sentence = \" :) A smile to end up your day with. =) What is making you happy :)))))) these days? <3 :DDDD \"\n",
        "\n",
        "characters =  [\":\\)\", \";\\)\", \"=\\)\", \":\\)\\)\\)\\)\\)\\)\", \":D\", \":DDDD\"]\n",
        "\n",
        "# substitute the characters with happy using a join operator -> | represents a logical OR\n",
        "sub_sentence = re.sub(\"|\".join(characters), \"happy\", sentence)\n",
        "print(sub_sentence) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " happy A smile to end up your day with. happy What is making you happy happy))))) these days? <3 happyDDD \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MIO1qXzkKRfe",
        "colab_type": "code",
        "outputId": "51f9f2e5-1f1b-488f-8496-5fb80f6ccdfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "cell_type": "code",
      "source": [
        "## Question 2\n",
        "\n",
        "# download the file from the google drive\n",
        "\n",
        "file_id_2 = '1hTJGWBXgVSBZlZ8klcVz7T59LeH7ncIq'\n",
        "downloaded_2 = drive.CreateFile({'id': file_id})\n",
        "india = downloaded_2.GetContentString()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-71f2bd7e8a64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfile_id_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1hTJGWBXgVSBZlZ8klcVz7T59LeH7ncIq'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdownloaded_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCreateFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfile_id\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mindia\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownloaded_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetContentString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'drive' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "fCKDyvO6Pt84",
        "colab_type": "code",
        "outputId": "d567f7fe-ff30-46f9-e0fd-e5b7118aca88",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "cell_type": "code",
      "source": [
        "# local upload\n",
        "from google.colab import files\n",
        "\n",
        "text = files.upload()\n",
        "\n",
        "for fn in text.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(text[fn])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9326a48f-ffaf-4307-bda0-f12da3fa3f7a\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-9326a48f-ffaf-4307-bda0-f12da3fa3f7a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving india.rtf to india (2).rtf\n",
            "User uploaded file \"india.rtf\" with length 11154 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Fx7N4KCZRaBc",
        "colab_type": "code",
        "outputId": "5c9310a3-371a-47d7-c9e1-19835a8f3918",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install striprtf\n",
        "import striprtf\n",
        "striprtf()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: striprtf in /usr/local/lib/python3.6/dist-packages (0.0.3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-1d7589f57055>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install striprtf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstriprtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstriprtf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "96rr38_rWtas",
        "colab_type": "code",
        "outputId": "187b4d8b-a2a1-4a67-83b0-ba9e7fab44bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "cell_type": "code",
      "source": [
        "stripRtf(text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-0e49615bed43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstripRtf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'stripRtf' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "d2ClT9gnnVtX",
        "colab_type": "code",
        "outputId": "dbca5430-d7a2-4f04-9b44-acdba0df8a3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        }
      },
      "cell_type": "code",
      "source": [
        "## Question 1.2: Find every occurrence of a number and replace it with the word digit in this document\n",
        "\n",
        "# As I'm currently not able to get this stupid rtf converter tool up and running, this exercise is done manually\n",
        "# Question: instances such as \"sixth\" or \"millenium\" are they numbers?\n",
        "# Question: 18 should be replaced by digit or digitdigit?\n",
        "\n",
        "text = \"\"\"India (IAST: Bhārat), also known as the Republic of India (IAST: BhāratGaṇarājya),\n",
        "[18][e]\n",
        "is a country in South Asia. It is the seventh largest country by area\n",
        "and with more than 1.3 billion people, it is the second most populouscountry and\n",
        "the most populous democracy in the world. Bounded by the Indian Ocean on the\n",
        "south, the Arabian Seaon the southwest, and the Bay of Bengal on the southeast,\n",
        "it shares land borders with Pakistan to the west;\n",
        "\n",
        "[f] China, Nepal, and Bhutan to the\n",
        "northeast; and Bangladesh and Myanmar to the east. In the Indian Ocean, India is\n",
        "in the vicinity of Sri Lanka and the Maldives, while its Andaman and Nicobar\n",
        "Islands share a maritime border with Thailandand Indonesia.\n",
        "The Indian subcontinent was home to the urban Indus Valley Civilisation of the 3rd\n",
        "millennium BCE. In the following millennium, the oldest scriptures associated\n",
        "with Hinduism began to be composed. Social stratification, based on caste,\n",
        "emerged in the first millennium BCE, and Buddhism and Jainism arose. Early\n",
        "political consolidations took place under the Maurya and Gupta empires; later\n",
        "peninsular Middle Kingdoms influenced cultures as far as Southeast Asia. In the\n",
        "medieval era, Judaism, Zoroastrianism, Christianity, and Islam arrived,\n",
        "and Sikhism emerged, all adding to the region's diverse culture. Much of the north\n",
        "fell to the Delhi Sultanate; the south was united under the Vijayanagara Empire.\n",
        "The economy expanded in the 17th century in the Mughal Empire. In the mid-18th\n",
        "century, the subcontinent came under British East India Company rule, and in the\n",
        "mid-19th under British crown rule. A nationalist movement emerged in the late\n",
        "19th century, which later, under Mahatma Gandhi, was noted for nonviolent\n",
        "resistance and led to India's independence in 1947.\n",
        "In 2017, the Indian economy was the world's sixth largest by\n",
        "nominal GDP[19] and third largest by purchasing power parity.\n",
        "\n",
        "[15] Following market-\n",
        "based economic reforms in 1991, India became one of the fastest-growing major\n",
        "\n",
        "economies and is considered a newly industrialised country. However, it continues\n",
        "to face the challenges of poverty, corruption, malnutrition, and inadequate public\n",
        "healthcare. A nuclear weapons state and regional power, it has the second largest\n",
        "standing army in the world and ranks fifth in military expenditure among nations.\n",
        "India is a federal republic governed under a parliamentary system and consists\n",
        "of 29 states and 7 union territories. A pluralistic, multilingual and multi-ethnic\n",
        "society, it is also home to a diversity of wildlife in a variety of protected habitats.\"\"\"\n",
        "\n",
        "sub_text = re.sub(r'\\w\\d|\\d\\.', \"digit\", text)\n",
        "print(sub_text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "India (IAST: Bhārat), also known as the Republic of India (IAST: BhāratGaṇarājya),\n",
            "[digit][e]\n",
            "is a country in South Asia. It is the seventh largest country by area\n",
            "and with more than digit3 billion people, it is the second most populouscountry and\n",
            "the most populous democracy in the world. Bounded by the Indian Ocean on the\n",
            "south, the Arabian Seaon the southwest, and the Bay of Bengal on the southeast,\n",
            "it shares land borders with Pakistan to the west;\n",
            "\n",
            "[f] China, Nepal, and Bhutan to the\n",
            "northeast; and Bangladesh and Myanmar to the east. In the Indian Ocean, India is\n",
            "in the vicinity of Sri Lanka and the Maldives, while its Andaman and Nicobar\n",
            "Islands share a maritime border with Thailandand Indonesia.\n",
            "The Indian subcontinent was home to the urban Indus Valley Civilisation of the 3rd\n",
            "millennium BCE. In the following millennium, the oldest scriptures associated\n",
            "with Hinduism began to be composed. Social stratification, based on caste,\n",
            "emerged in the first millennium BCE, and Buddhism and Jainism arose. Early\n",
            "political consolidations took place under the Maurya and Gupta empires; later\n",
            "peninsular Middle Kingdoms influenced cultures as far as Southeast Asia. In the\n",
            "medieval era, Judaism, Zoroastrianism, Christianity, and Islam arrived,\n",
            "and Sikhism emerged, all adding to the region's diverse culture. Much of the north\n",
            "fell to the Delhi Sultanate; the south was united under the Vijayanagara Empire.\n",
            "The economy expanded in the digitth century in the Mughal Empire. In the mid-digitth\n",
            "century, the subcontinent came under British East India Company rule, and in the\n",
            "mid-digitth under British crown rule. A nationalist movement emerged in the late\n",
            "digitth century, which later, under Mahatma Gandhi, was noted for nonviolent\n",
            "resistance and led to India's independence in digitdigit.\n",
            "In digitdigit, the Indian economy was the world's sixth largest by\n",
            "nominal GDP[digit] and third largest by purchasing power parity.\n",
            "\n",
            "[digit] Following market-\n",
            "based economic reforms in digitdigit, India became one of the fastest-growing major\n",
            "\n",
            "economies and is considered a newly industrialised country. However, it continues\n",
            "to face the challenges of poverty, corruption, malnutrition, and inadequate public\n",
            "healthcare. A nuclear weapons state and regional power, it has the second largest\n",
            "standing army in the world and ranks fifth in military expenditure among nations.\n",
            "India is a federal republic governed under a parliamentary system and consists\n",
            "of digit states and 7 union territories. A pluralistic, multilingual and multi-ethnic\n",
            "society, it is also home to a diversity of wildlife in a variety of protected habitats.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LUccYdgpf7lV",
        "colab_type": "code",
        "outputId": "29f953cc-c922-4ba6-85cc-15ac8c68c93e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "## Question 1.3: Create a regex for identifying punctuation marks (all kinds)\n",
        "\n",
        "# Idea: create a regex, that returns all possible punctuation marks, with various exceptions:\n",
        "# E.g. a numeric delimiter (0.1 is not really punctuation)\n",
        "\n",
        "sentence = 'Hi there, i\\'m looking for punctuation with 0.0 accuracy.'\n",
        "regex_punct = r'\\.(?!\\d)|\\,|\\!|\\?|\\|\\:|\\;|\\''\n",
        "re.findall(regex_punct, sentence)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[',', \"'\", '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "qchfOW8wiqfQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Basic Text Processing (pre-processing pipeline)"
      ]
    },
    {
      "metadata": {
        "id": "xR1PUahqi7kh",
        "colab_type": "code",
        "outputId": "7f4d1a2d-02f8-47ce-aa88-5979c23cac2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "categories = ['sci.med']\n",
        "twenty_train = fetch_20newsgroups(subset='train',\n",
        "                                  categories=categories, \n",
        "                                  shuffle=True, \n",
        "                                  random_state=42)\n",
        "sentence = twenty_train['data'][15]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "eMKiN4bxj1LR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Lemmatization__  \n",
        "_Previous to using both the Stemmer and the Lemmatizer it is required to install  the wordnet and punkt datafiles using the following command: nltk.download()_"
      ]
    },
    {
      "metadata": {
        "id": "CGzq9Av8mggy",
        "colab_type": "code",
        "outputId": "fd2d7013-a6db-4a6d-aa8b-32570c33488d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        }
      },
      "cell_type": "code",
      "source": [
        "nltk.download()\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer # install wordnet\n",
        "from nltk.stem import PorterStemmer # install punkt\n",
        "\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "porter_stemmer = PorterStemmer()\n",
        "\n",
        "word_data = sentence\n",
        "nltk_tokens = nltk.word_tokenize(word_data)\n",
        "print(\"Word net Lemmatizer\")\n",
        "for w in nltk_tokens:\n",
        "       if w != wordnet_lemmatizer.lemmatize(w):\n",
        "          print(\"Actual: %s  Lemma: %s\"  % (w,wordnet_lemmatizer.lemmatize(w)))\n",
        "        \n",
        "# inspired from https://www.tutorialspoint.com/python/python_stemming_and_lemmatization.htm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> l\n",
            "Packages:\n",
            "  [ ] abc................. Australian Broadcasting Commission 2006\n",
            "  [ ] alpino.............. Alpino Dutch Treebank\n",
            "  [ ] averaged_perceptron_tagger Averaged Perceptron Tagger\n",
            "  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n",
            "  [ ] basque_grammars..... Grammars for Basque\n",
            "  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n",
            "                           Extraction Systems in Biology)\n",
            "  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n",
            "  [ ] book_grammars....... Grammars from NLTK Book\n",
            "  [ ] brown............... Brown Corpus\n",
            "  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n",
            "  [ ] cess_cat............ CESS-CAT Treebank\n",
            "  [ ] cess_esp............ CESS-ESP Treebank\n",
            "  [ ] chat80.............. Chat-80 Data Files\n",
            "  [ ] city_database....... City Database\n",
            "  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n",
            "  [ ] comparative_sentences Comparative Sentence Dataset\n",
            "  [ ] comtrans............ ComTrans Corpus Sample\n",
            "  [ ] conll2000........... CONLL 2000 Chunking Corpus\n",
            "  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BdNn6_nxj3iW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Stemming__  \n",
        "_Previous to using both the Stemmer and the Lemmatizer it is required to install  the wordnet and punkt datafiles using the following command: nltk.download()_"
      ]
    },
    {
      "metadata": {
        "id": "QnvI72ANjC6h",
        "colab_type": "code",
        "outputId": "abefc2e3-e23a-46bd-be2a-94e657e45b15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2136
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"\\nPorter Stemmer\")\n",
        "for w in nltk_tokens:\n",
        "       if w != porter_stemmer.stem(w):\n",
        "          print(\"Actual: %s  Stem: %s\"  % (w,porter_stemmer.stem(w)))\n",
        "        \n",
        "# inspired from https://www.tutorialspoint.com/python/python_stemming_and_lemmatization.htm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Porter Stemmer\n",
            "Actual: From  Stem: from\n",
            "Actual: Gordon  Stem: gordon\n",
            "Actual: Banks  Stem: bank\n",
            "Actual: Subject  Stem: subject\n",
            "Actual: Update  Stem: updat\n",
            "Actual: Help  Stem: help\n",
            "Actual: was  Stem: wa\n",
            "Actual: What  Stem: what\n",
            "Actual: This  Stem: thi\n",
            "Actual: Lyme  Stem: lyme\n",
            "Actual: Article-I.D  Stem: article-i.d\n",
            "Actual: Reply-To  Stem: reply-to\n",
            "Actual: Gordon  Stem: gordon\n",
            "Actual: Banks  Stem: bank\n",
            "Actual: Organization  Stem: organ\n",
            "Actual: Univ  Stem: univ\n",
            "Actual: Pittsburgh  Stem: pittsburgh\n",
            "Actual: Computer  Stem: comput\n",
            "Actual: Science  Stem: scienc\n",
            "Actual: Lines  Stem: line\n",
            "Actual: article  Stem: articl\n",
            "Actual: 1993Mar29.181958.3224  Stem: 1993mar29.181958.3224\n",
            "Actual: John  Stem: john\n",
            "Actual: Setel  Stem: setel\n",
            "Actual: O'Donnell  Stem: o'donnel\n",
            "Actual: writes  Stem: write\n",
            "Actual: posting  Stem: post\n",
            "Actual: Physicians  Stem: physician\n",
            "Actual: Lyme  Stem: lyme\n",
            "Actual: literature  Stem: literatur\n",
            "Actual: Steere  Stem: steer\n",
            "Actual: Patients  Stem: patient\n",
            "Actual: correctly  Stem: correctli\n",
            "Actual: diagnosed  Stem: diagnos\n",
            "Actual: treated  Stem: treat\n",
            "Actual: Why  Stem: whi\n",
            "Actual: Steere  Stem: steer\n",
            "Actual: doing  Stem: do\n",
            "Actual: this  Stem: thi\n",
            "Actual: acting  Stem: act\n",
            "Actual: After  Stem: after\n",
            "Actual: discoverer  Stem: discover\n",
            "Actual: Lyme  Stem: lyme\n",
            "Actual: intents  Stem: intent\n",
            "Actual: purposes  Stem: purpos\n",
            "Actual: famous  Stem: famou\n",
            "Actual: Lyme  Stem: lyme\n",
            "Actual: gets  Stem: get\n",
            "Actual: famous  Stem: famou\n",
            "Actual: Steere  Stem: steer\n",
            "Actual: gets  Stem: get\n",
            "Actual: motive  Stem: motiv\n",
            "Actual: easy  Stem: easi\n",
            "Actual: physicians  Stem: physician\n",
            "Actual: everything  Stem: everyth\n",
            "Actual: everything  Stem: everyth\n",
            "Actual: There  Stem: there\n",
            "Actual: involved  Stem: involv\n",
            "Actual: computer  Stem: comput\n",
            "Actual: engineer  Stem: engin\n",
            "Actual: Jim  Stem: jim\n",
            "Actual: was  Stem: wa\n",
            "Actual: building  Stem: build\n",
            "Actual: computer  Stem: comput\n",
            "Actual: manufacturing  Stem: manufactur\n",
            "Actual: company  Stem: compani\n",
            "Actual: Lyme  Stem: lyme\n",
            "Actual: several  Stem: sever\n",
            "Actual: years  Stem: year\n",
            "Actual: near-total  Stem: near-tot\n",
            "Actual: disability  Stem: disabl\n",
            "Actual: partially  Stem: partial\n",
            "Actual: company  Stem: compani\n",
            "Actual: failed  Stem: fail\n",
            "Actual: taking  Stem: take\n",
            "Actual: jobs  Stem: job\n",
            "Actual: savings  Stem: save\n",
            "Actual: everything  Stem: everyth\n",
            "Actual: worked  Stem: work\n",
            "Actual: years  Stem: year\n",
            "Actual: lucky  Stem: lucki\n",
            "Actual: ones  Stem: one\n",
            "Actual: Lyme  Stem: lyme\n",
            "Actual: foundation  Stem: foundat\n",
            "Actual: full-time  Stem: full-tim\n",
            "Actual: persistent  Stem: persist\n",
            "Actual: infection  Stem: infect\n",
            "Actual: variety  Stem: varieti\n",
            "Actual: sypmtoms  Stem: sypmtom\n",
            "Actual: And  Stem: and\n",
            "Actual: try  Stem: tri\n",
            "Actual: Lyme  Stem: lyme\n",
            "Actual: literature  Stem: literatur\n",
            "Actual: Well  Stem: well\n",
            "Actual: has  Stem: ha\n",
            "Actual: happened  Stem: happen\n",
            "Actual: necessarily  Stem: necessarili\n",
            "Actual: objective  Stem: object\n",
            "Actual: source  Stem: sourc\n",
            "Actual: information  Stem: inform\n",
            "Actual: focussed  Stem: focuss\n",
            "Actual: this  Stem: thi\n",
            "Actual: emotionally  Stem: emot\n",
            "Actual: involved  Stem: involv\n",
            "Actual: advising  Stem: advis\n",
            "Actual: people  Stem: peopl\n",
            "Actual: Lyme  Stem: lyme\n",
            "Actual: Certainly  Stem: certainli\n",
            "Actual: advocacy  Stem: advocaci\n",
            "Actual: Lyme  Stem: lyme\n",
            "Actual: people  Stem: peopl\n",
            "Actual: very  Stem: veri\n",
            "Actual: effective  Stem: effect\n",
            "Actual: Gordon  Stem: gordon\n",
            "Actual: Banks  Stem: bank\n",
            "Actual: N3JXP  Stem: n3jxp\n",
            "Actual: Skepticism  Stem: skeptic\n",
            "Actual: chastity  Stem: chastiti\n",
            "Actual: shameful  Stem: shame\n",
            "Actual: surrender  Stem: surrend\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qxnmsRyFr0Ys",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Tokenization__  \n",
        "_Some text_"
      ]
    },
    {
      "metadata": {
        "id": "PtI1c26Nr9Fy",
        "colab_type": "code",
        "outputId": "597bb114-2dd2-49eb-83bb-bc37b653e6e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "cell_type": "code",
      "source": [
        "# word token\n",
        "print(nltk_tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-f34d5eef2f25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'nltk_tokens' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "KtoHYHlIsn-Q",
        "colab_type": "code",
        "outputId": "eb77e960-db08-4fe1-c738-8dbb12a21537",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "cell_type": "code",
      "source": [
        "# sentence tokens\n",
        "sentence_tokens = nltk.sen_tokenize(word_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-cae450e08dcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentence_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msen_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'nltk' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "3qTFgS_ptro8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}